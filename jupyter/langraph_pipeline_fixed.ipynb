{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4421e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet openai python-dotenv pillow pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup imports and client\n",
    "from dotenv import load_dotenv\n",
    "import os, io, base64, json\n",
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "except Exception:\n",
    "    OpenAI = None\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_KEY = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(api_key=OPENAI_KEY) if (OpenAI and OPENAI_KEY) else None\n",
    "\n",
    "if client is None:\n",
    "    print('OpenAI client not initialized; falling back to heuristics only')\n",
    "else:\n",
    "    print('OpenAI client initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8460a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: encode image to base64\n",
    "def encode_image_to_base64(image_path: str) -> str:\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    buf = io.BytesIO()\n",
    "    img.save(buf, format='JPEG')\n",
    "    return base64.b64encode(buf.getvalue()).decode('utf-8')\n",
    "\n",
    "# Heuristic fallback\n",
    "def heuristic_classify(image_path: str) -> dict:\n",
    "    category = 'other'\n",
    "    explanation = 'Fallback heuristics used.'\n",
    "    conf = 0.5\n",
    "    name = os.path.basename(image_path).lower()\n",
    "    if any(k in name for k in ['receipt','invoice','bill']):\n",
    "        return {'category': 'receipt', 'confidence': 0.6, 'explanation': 'Filename suggests a receipt.'}\n",
    "    try:\n",
    "        import pytesseract\n",
    "        img = Image.open(image_path)\n",
    "        text = pytesseract.image_to_string(img).lower()\n",
    "        if any(k in text for k in ['total','subtotal','receipt','amount']):\n",
    "            return {'category': 'receipt', 'confidence': 0.85, 'explanation': 'OCR detected receipt-like text.'}\n",
    "        if any(k in text for k in ['prescription','rx','clinic','hospital','patient']):\n",
    "            return {'category': 'health', 'confidence': 0.75, 'explanation': 'OCR detected medical text.'}\n",
    "    except Exception:\n",
    "        pass\n",
    "    return {'category': category, 'confidence': conf, 'explanation': explanation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0d04f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core classify function using OpenAI if available\n",
    "def classify_image(image_path: str, allowed_categories=None, model='gpt-4o') -> dict:\n",
    "    if allowed_categories is None:\n",
    "        allowed_categories = ['scenery', 'food', 'receipt', 'health', 'collectable', 'other']\n",
    "    if client is None:\n",
    "        return heuristic_classify(image_path)\n",
    "\n",
    "    system_prompt = ('You are an expert image classification assistant. The allowed output categories are: ' + ', '.join(allowed_categories) + '.\\n'\n",
    "                    + 'Return exactly a JSON object with keys: category (one of allowed categories), confidence (0.0-1.0), and explanation (short text). Do not add other text.')\n",
    "    user_prompt = 'Classify the attached image into one of the categories and keep the output as strict JSON.'\n",
    "\n",
    "    b64 = encode_image_to_base64(image_path)\n",
    "    image_content = { 'type': 'image_url', 'image_url': {'url': f'data:image/jpeg;base64,{b64}'} }\n",
    "    messages = [ {'role': 'system', 'content': system_prompt}, {'role': 'user', 'content': [{'type': 'text', 'text': user_prompt}, image_content]} ]\n",
    "\n",
    "    try:\n",
    "        resp = client.chat.completions.create(model=model, messages=messages, max_tokens=200)\n",
    "        raw = resp.choices[0].message.content\n",
    "        try:\n",
    "            parsed = json.loads(raw)\n",
    "            if 'category' in parsed and parsed['category'] in allowed_categories:\n",
    "                return {'category': parsed['category'], 'confidence': parsed.get('confidence', 0.9), 'explanation': parsed.get('explanation','')}\n",
    "        except Exception:\n",
    "            raw_l = raw.lower()\n",
    "            for c in allowed_categories:\n",
    "                if c in raw_l:\n",
    "                    return {'category': c, 'confidence': 0.65, 'explanation': 'Found category word in model response.'}\n",
    "            return {'category': 'other', 'confidence': 0.3, 'explanation': 'No category detected in model response.'}\n",
    "    except Exception as e:\n",
    "        print('OpenAI error:', e)\n",
    "        return heuristic_classify(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd667ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "example_image_path = r\"C:\\Users\\Ron\\temp\\IMG_6094.JPG\"\n",
    "result = classify_image(example_image_path, model='gpt-4o')\n",
    "print('Category:', result.get('category'))\n",
    "print('Confidence:', result.get('confidence'))\n",
    "print('Explanation:', result.get('explanation'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
