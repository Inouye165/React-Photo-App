const fs = require("fs");
const path = require("path");
const cp = require("child_process");

const repo = process.cwd();
const head = cp.execSync("git rev-parse HEAD", { encoding: "utf8" }).trim();
const files = cp.execSync("git ls-files", { encoding: "utf8" }).split(/\r?\n/).filter(Boolean);

const extOf = (p) => path.extname(p).toLowerCase();
const baseOf = (p) => path.basename(p);
const isLikelyBinary = (buf) => {
  if (!buf || buf.length === 0) return false;
  const sample = buf.subarray(0, Math.min(buf.length, 8000));
  for (let i = 0; i < sample.length; i++) if (sample[i] === 0) return true;
  return false;
};

const isTestFile = (p) => /(^|\/)(__tests__|tests)(\/|$)/.test(p) || /\.(test|spec)\./.test(p) || /e2e\//.test(p);
const isDocsLike = (p) => {
  const ext = extOf(p);
  return ext === ".md" || ext === ".txt" || p.startsWith("docs/") || p.startsWith(".github/");
};
const isCodeLike = (p) => /\.(js|jsx|ts|tsx|cjs|mjs)$/.test(extOf(p));

const binaryExts = new Set([".png", ".jpg", ".jpeg", ".gif", ".webp", ".svg", ".heic", ".db", ".crt"]);

// Path/name level smells (senior hygiene / AI-iteration artifacts)
const fileNameSignals = [
  {
    severity: "HIGH",
    kind: "path",
    category: "Committed build output / generated artifacts",
    re: /(^|\/)(dist\/|playwright-report\/)/,
    detail: "Build outputs / reports are usually not committed (unless this repo intentionally vendors artifacts).",
  },
  {
    severity: "HIGH",
    kind: "path",
    category: "Committed database / runtime state",
    re: /(^|\/)(server\/server_photos\.(db|json)$|server\/working\/dev\.db$)/,
    detail: "Committing DB/state files is atypical for senior repo hygiene and can indicate iteration artifacts.",
  },
  {
    severity: "MEDIUM",
    kind: "path",
    category: "Large volume of iterative fix logs / work notes committed",
    re: /(^|\/)(docs\/history\/.*\.md$|.*_FIX_.*\.md$|.*_REPORT.*\.md$|.*_SUMMARY\.md$|.*_LOG\.md$|PROBLEM_LOG\.md$|docs\/error-handling-audit\.md$|docs\/DOCUMENTATION_AUDIT\.md$)/,
    detail: "Large quantities of narrative fix logs/checklists are more common in AI-assisted iteration than curated repos.",
  },
  {
    severity: "MEDIUM",
    kind: "path",
    category: "AI/editor tooling provenance doc committed",
    re: /(^|\/)(readme-\d{4}-\d{2}-\d{2}.*\.md$|\.github\/copilot-instructions\.md$)/,
    detail: "Docs explicitly tied to AI/editor tooling are strong signals of AI-assisted workflows.",
  },
  {
    severity: "LOW",
    kind: "path",
    category: "Ad-hoc outputs committed",
    re: /(^|\/)(git-history\.txt$|test_output\.txt$|file-picker-files\.txt$)/,
    detail: "Committed ad-hoc outputs are a mild repo-hygiene smell.",
  },
];

// Content-level assistant/provenance smells (docs-like)
const prosePatterns = [
  {
    severity: "HIGH",
    kind: "content",
    category: "Explicit AI tool authorship / provenance",
    re: /(generated by chatgpt|written by chatgpt|created with chatgpt|generated by cursor|cursor ai)/gi,
    why: "Direct provenance statements are strong indicators of AI-written content.",
  },
  {
    severity: "HIGH",
    kind: "content",
    category: "Assistant self-reference / LLM disclaimer",
    re: /(\bas an ai\b|\bI am an AI\b|\blanguage model\b|\bI (?:cannot|can(?:\u0027|\u2019)?t)\b)/gi,
    why: "Self-referential assistant phrasing rarely belongs in repo docs.",
  },
  {
    severity: "MEDIUM",
    kind: "content",
    category: "Copilot/AI remediation attribution",
    re: /(remediated by:\s*github copilot|fixed by:\s*github copilot|senior .* mode)/gi,
    why: "Attribution lines like this are unusual in typical engineering docs and suggest AI-assisted generation.",
  },
  {
    severity: "LOW",
    kind: "content",
    category: "Prompt-like all-caps directives",
    re: /(\bCRITICAL\b:?|\bIMPORTANT\b:?|\bMUST\b|\bNEVER\b|\bALWAYS\b)/g,
    why: "All-caps prompt-like instruction blocks often originate from agent prompts.",
  },
];

// Content-level prompt/agent directive smells in code/comments (don’t confuse with legit OpenAI usage)
const codeDirectivePatterns = [
  {
    severity: "MEDIUM",
    kind: "content",
    category: "Prompt/agent-like directives embedded",
    re: /(\bCRITICAL\b:?|\bMUST\b|\bNEVER\b|\bALWAYS\b).{0,160}/g,
    why: "Prompt-style directives inside code/comments can be a smell of LLM-driven edits or prompt copy/paste.",
  },
];

// Senior hygiene: committed env/workflow keys (even placeholders)
const secretPatterns = [
  {
    severity: "HIGH",
    kind: "content",
    category: "Env/workflow contains key-like fields",
    re: /(OPENAI_API_KEY\s*=|SUPABASE_SERVICE_ROLE_KEY\s*=|SUPABASE_ANON_KEY\s*=|VITE_SUPABASE_ANON_KEY\s*=|DATABASE_URL\s*=)/g,
    why: "Env/workflow files with key-like fields are sensitive; committing them (even placeholders) often correlates with rushed/automated iteration.",
  },
];

function lineEvidence(content, idx) {
  const before = content.slice(0, idx);
  const lineNo = before.split(/\r?\n/).length;
  const lines = content.split(/\r?\n/);
  const line = lines[lineNo - 1] || "";
  return { lineNo, line: line.trim().slice(0, 260) };
}

function isEnvOrWorkflowFile(rel) {
  const base = baseOf(rel);
  if (base.startsWith(".env")) return true;
  if (rel.startsWith(".github/workflows/") && /\.(yml|yaml)$/i.test(rel)) return true;
  return false;
}

const byFile = new Map();
for (const f of files) byFile.set(f, []);

for (const rel of files) {
  // path-level findings
  for (const s of fileNameSignals) {
    if (s.re.test(rel)) {
      byFile.get(rel).push({ severity: s.severity, kind: s.kind, category: s.category, detail: s.detail });
    }
  }

  const abs = path.join(repo, rel);
  let buf;
  try {
    buf = fs.readFileSync(abs);
  } catch (e) {
    byFile.get(rel).push({ severity: "MEDIUM", kind: "path", category: "Unreadable file", detail: "Failed to read: " + e.message });
    continue;
  }

  const ext = extOf(rel);
  if (binaryExts.has(ext) || isLikelyBinary(buf)) {
    byFile.get(rel).push({ severity: "LOW", kind: "path", category: "Binary file", detail: "Binary or non-text content; line-level scan skipped." });
    continue;
  }

  const content = buf.toString("utf8");

  if (isEnvOrWorkflowFile(rel)) {
    for (const p of secretPatterns) {
      p.re.lastIndex = 0;
      let hits = 0;
      let m;
      while ((m = p.re.exec(content)) && hits < 15) {
        const ev = lineEvidence(content, m.index);
        byFile.get(rel).push({ severity: p.severity, kind: p.kind, category: p.category, detail: p.why, evidence: "L" + ev.lineNo + ": " + ev.line });
        hits++;
      }
    }
  }

  if (isDocsLike(rel)) {
    for (const p of prosePatterns) {
      p.re.lastIndex = 0;
      let hits = 0;
      let m;
      while ((m = p.re.exec(content)) && hits < 10) {
        const ev = lineEvidence(content, m.index);
        byFile.get(rel).push({ severity: p.severity, kind: p.kind, category: p.category, detail: p.why, evidence: "L" + ev.lineNo + ": " + ev.line });
        hits++;
      }
    }
  }

  if (isCodeLike(rel) && !isTestFile(rel)) {
    for (const p of codeDirectivePatterns) {
      p.re.lastIndex = 0;
      let hits = 0;
      let m;
      while ((m = p.re.exec(content)) && hits < 10) {
        const ev = lineEvidence(content, m.index);
        byFile.get(rel).push({ severity: p.severity, kind: p.kind, category: p.category, detail: p.why, evidence: "L" + ev.lineNo + ": " + ev.line });
        hits++;
      }
    }
  }
}

const severityRank = { HIGH: 3, MEDIUM: 2, LOW: 1 };
function sortFindings(list) {
  return list
    .slice()
    .sort((a, b) => {
      const r = (severityRank[b.severity] || 0) - (severityRank[a.severity] || 0);
      if (r) return r;
      const ea = a.evidence || "";
      const eb = b.evidence || "";
      if (ea !== eb) return ea.localeCompare(eb);
      return (a.category || "").localeCompare(b.category || "");
    });
}

const now = new Date().toISOString();
let out = "";
out += "# Per-file AI Smell Audit (all tracked files)\n\n";
out += "- Repo: React-Photo-App\n";
out += "- Commit: " + head + "\n";
out += "- Generated: " + now + "\n";
out += "- Tracked files audited: " + files.length + "\n\n";
out += "## How to use\n\n";
out += "- Each section is a **file**.\n";
out += "- Each bullet with `L###:` is a **line number inside that file**.\n";
out += "- In VS Code/Cursor: open the file, press **Ctrl+G**, type the number.\n\n";

for (const rel of files) {
  out += "## " + rel + "\n\n";
  const items = sortFindings(byFile.get(rel) || []);

  // dedupe identical findings
  const seen = new Set();
  const deduped = [];
  for (const it of items) {
    const key = [it.severity, it.category, it.evidence || "", it.detail || ""].join("||");
    if (seen.has(key)) continue;
    seen.add(key);
    deduped.push(it);
  }

  if (!deduped.length) {
    out += "- No AI-smell findings triggered by the current heuristics.\n\n";
    continue;
  }

  for (const it of deduped) {
    out += "- **" + it.severity + " / " + it.category + "**";
    out += it.evidence ? " — " + it.evidence : " (path-level)";
    out += "\n";
    out += "  - " + it.detail + "\n";
  }

  out += "\n";
}

fs.writeFileSync(path.join(repo, "AI_CODE_REVIEW.md"), out, "utf8");
console.log("Wrote AI_CODE_REVIEW.md in per-file format");

